(C:\Users\User\Anaconda3\envs\py35) C:\Users\User>python C:\Users\User\Documents\CENGs\Thesis\edanur\BadaNet\EENets\main.py --epochs 20 --filters 4 --lamb 1.05
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 4, 28, 28]              40
       BatchNorm2d-2            [-1, 4, 28, 28]               8
              ReLU-3            [-1, 4, 28, 28]               0
            Conv2d-4            [-1, 4, 28, 28]             148
       BatchNorm2d-5            [-1, 4, 28, 28]               8
              ReLU-6            [-1, 4, 28, 28]               0
            Conv2d-7            [-1, 4, 28, 28]             148
 AdaptiveAvgPool2d-8              [-1, 4, 1, 1]               0
            Linear-9                   [-1, 10]              50
          Softmax-10                   [-1, 10]               0
           Linear-11                    [-1, 1]               5
          Sigmoid-12                    [-1, 1]               0
      BatchNorm2d-13            [-1, 4, 28, 28]               8
             ReLU-14            [-1, 4, 28, 28]               0
           Conv2d-15            [-1, 8, 14, 14]             296
      BatchNorm2d-16            [-1, 8, 14, 14]              16
             ReLU-17            [-1, 8, 14, 14]               0
           Conv2d-18            [-1, 8, 14, 14]             584
           Conv2d-19            [-1, 8, 14, 14]              40
AdaptiveAvgPool2d-20              [-1, 8, 1, 1]               0
           Linear-21                   [-1, 10]              90
          Softmax-22                   [-1, 10]               0
           Linear-23                    [-1, 1]               9
          Sigmoid-24                    [-1, 1]               0
      BatchNorm2d-25            [-1, 8, 14, 14]              16
             ReLU-26            [-1, 8, 14, 14]               0
           Conv2d-27             [-1, 16, 7, 7]           1,168
      BatchNorm2d-28             [-1, 16, 7, 7]              32
             ReLU-29             [-1, 16, 7, 7]               0
           Conv2d-30             [-1, 16, 7, 7]           2,320
           Conv2d-31             [-1, 16, 7, 7]             144
      BatchNorm2d-32             [-1, 16, 7, 7]              32
             ReLU-33             [-1, 16, 7, 7]               0
AdaptiveAvgPool2d-34             [-1, 16, 1, 1]               0
           Linear-35                   [-1, 10]             170
          Softmax-36                   [-1, 10]               0
================================================================
Total params: 5,332
Trainable params: 5,332
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.34
Params size (MB): 0.02
Estimated Total Size (MB): 0.36
----------------------------------------------------------------
 1:Test set avg time: 0.6441msec Avg loss: 1.2610, Avg cost: 0.8789, Exits: <322,1236,8442>, Accuracy:89.37%
 2:Test set avg time: 0.6369msec Avg loss: 1.1711, Avg cost: 0.8987, Exits: <118,1222,8660>, Accuracy:92.98%
 3:Test set avg time: 0.6700msec Avg loss: 1.1524, Avg cost: 0.8940, Exits: <53,1366,8581>, Accuracy:93.98%
 4:Test set avg time: 0.6641msec Avg loss: 1.0862, Avg cost: 0.9023, Exits: <60,1246,8694>, Accuracy:96.11%
 5:Test set avg time: 0.6638msec Avg loss: 1.0720, Avg cost: 0.8964, Exits: <125,1245,8630>, Accuracy:96.40%
 6:Test set avg time: 0.6100msec Avg loss: 1.0572, Avg cost: 0.9013, Exits: <112,1194,8694>, Accuracy:96.82%
 7:Test set avg time: 0.6284msec Avg loss: 1.0548, Avg cost: 0.9073, Exits: <66,1171,8763>, Accuracy:96.96%
 8:Test set avg time: 0.6272msec Avg loss: 1.1058, Avg cost: 0.8876, Exits: <46,1462,8492>, Accuracy:96.22%
 9:Test set avg time: 0.6280msec Avg loss: 1.0909, Avg cost: 0.8832, Exits: <87,1470,8443>, Accuracy:96.36%
10:Test set avg time: 0.6105msec Avg loss: 1.0621, Avg cost: 0.8804, Exits: <68,1532,8400>, Accuracy:97.01%
11:Test set avg time: 0.6194msec Avg loss: 1.0923, Avg cost: 0.8520, Exits: <68,1915,8017>, Accuracy:96.37%
12:Test set avg time: 0.5887msec Avg loss: 1.1390, Avg cost: 0.8300, Exits: <167,2090,7743>, Accuracy:95.43%
13:Test set avg time: 0.6017msec Avg loss: 1.3077, Avg cost: 0.8198, Exits: <101,2310,7589>, Accuracy:94.14%
14:Test set avg time: 0.6297msec Avg loss: 1.0472, Avg cost: 0.8375, Exits: <157,2001,7842>, Accuracy:96.57%
15:Test set avg time: 0.6147msec Avg loss: 1.2036, Avg cost: 0.8179, Exits: <203,2208,7589>, Accuracy:95.10%
16:Test set avg time: 0.6189msec Avg loss: 0.9920, Avg cost: 0.8477, Exits: <195,1816,7989>, Accuracy:97.03%
17:Test set avg time: 0.6269msec Avg loss: 1.1748, Avg cost: 0.8257, Exits: <111,2217,7672>, Accuracy:95.43%
18:Test set avg time: 0.6036msec Avg loss: 0.9897, Avg cost: 0.8560, Exits: <132,1782,8086>, Accuracy:97.33%
19:Test set avg time: 0.5975msec Avg loss: 1.0068, Avg cost: 0.8383, Exits: <225,1906,7869>, Accuracy:96.84%
20:Test set avg time: 0.5936msec Avg loss: 0.9856, Avg cost: 0.8535, Exits: <168,1771,8061>, Accuracy:97.53%
Best avg loss: 0.9856, avg cost: 0.8535, Accuracy:97.53%
