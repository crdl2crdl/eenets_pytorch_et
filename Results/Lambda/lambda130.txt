(C:\Users\User\Anaconda3\envs\py35) C:\Users\User>python C:\Users\User\Documents\CENGs\Thesis\edanur\BadaNet\EENets\main.py --epochs 20 --filters 4 --lamb 1.3
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 4, 28, 28]              40
       BatchNorm2d-2            [-1, 4, 28, 28]               8
              ReLU-3            [-1, 4, 28, 28]               0
            Conv2d-4            [-1, 4, 28, 28]             148
       BatchNorm2d-5            [-1, 4, 28, 28]               8
              ReLU-6            [-1, 4, 28, 28]               0
            Conv2d-7            [-1, 4, 28, 28]             148
 AdaptiveAvgPool2d-8              [-1, 4, 1, 1]               0
            Linear-9                   [-1, 10]              50
          Softmax-10                   [-1, 10]               0
           Linear-11                    [-1, 1]               5
          Sigmoid-12                    [-1, 1]               0
      BatchNorm2d-13            [-1, 4, 28, 28]               8
             ReLU-14            [-1, 4, 28, 28]               0
           Conv2d-15            [-1, 8, 14, 14]             296
      BatchNorm2d-16            [-1, 8, 14, 14]              16
             ReLU-17            [-1, 8, 14, 14]               0
           Conv2d-18            [-1, 8, 14, 14]             584
           Conv2d-19            [-1, 8, 14, 14]              40
AdaptiveAvgPool2d-20              [-1, 8, 1, 1]               0
           Linear-21                   [-1, 10]              90
          Softmax-22                   [-1, 10]               0
           Linear-23                    [-1, 1]               9
          Sigmoid-24                    [-1, 1]               0
      BatchNorm2d-25            [-1, 8, 14, 14]              16
             ReLU-26            [-1, 8, 14, 14]               0
           Conv2d-27             [-1, 16, 7, 7]           1,168
      BatchNorm2d-28             [-1, 16, 7, 7]              32
             ReLU-29             [-1, 16, 7, 7]               0
           Conv2d-30             [-1, 16, 7, 7]           2,320
           Conv2d-31             [-1, 16, 7, 7]             144
      BatchNorm2d-32             [-1, 16, 7, 7]              32
             ReLU-33             [-1, 16, 7, 7]               0
AdaptiveAvgPool2d-34             [-1, 16, 1, 1]               0
           Linear-35                   [-1, 10]             170
          Softmax-36                   [-1, 10]               0
================================================================
Total params: 5,332
Trainable params: 5,332
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.34
Params size (MB): 0.02
Estimated Total Size (MB): 0.36
----------------------------------------------------------------
 1:Test set avg time: 0.4944msec Avg loss: 1.5298, Avg cost: 0.2598, Exits: <12,9988,0>, Accuracy:58.69%
 2:Test set avg time: 0.4673msec Avg loss: 1.2267, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:70.76%
 3:Test set avg time: 0.4805msec Avg loss: 1.1753, Avg cost: 0.2680, Exits: <0,9892,108>, Accuracy:72.67%
 4:Test set avg time: 0.4850msec Avg loss: 1.3125, Avg cost: 0.2601, Exits: <0,9999,1>, Accuracy:68.99%
 5:Test set avg time: 0.4784msec Avg loss: 1.1693, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:72.14%
 6:Test set avg time: 0.4789msec Avg loss: 0.9736, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:79.54%
 7:Test set avg time: 0.4753msec Avg loss: 1.3271, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:67.94%
 8:Test set avg time: 0.4656msec Avg loss: 0.8656, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:83.75%
 9:Test set avg time: 0.4803msec Avg loss: 0.7923, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:86.36%
10:Test set avg time: 0.4822msec Avg loss: 0.9888, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:79.18%
11:Test set avg time: 0.4850msec Avg loss: 1.0984, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:76.00%
12:Test set avg time: 0.4886msec Avg loss: 0.7775, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:86.28%
13:Test set avg time: 0.4858msec Avg loss: 0.7422, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:87.89%
14:Test set avg time: 0.4764msec Avg loss: 0.6961, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:89.09%
15:Test set avg time: 0.4848msec Avg loss: 0.7476, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:87.48%
16:Test set avg time: 0.4702msec Avg loss: 0.7938, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:86.32%
17:Test set avg time: 0.4973msec Avg loss: 0.6669, Avg cost: 0.2601, Exits: <0,9999,1>, Accuracy:90.33%
18:Test set avg time: 0.4850msec Avg loss: 0.7043, Avg cost: 0.2600, Exits: <0,10000,0>, Accuracy:89.13%
19:Test set avg time: 0.4825msec Avg loss: 0.6900, Avg cost: 0.2602, Exits: <0,9997,3>, Accuracy:89.45%
20:Test set avg time: 0.4873msec Avg loss: 0.7705, Avg cost: 0.2603, Exits: <0,9996,4>, Accuracy:86.96%
Best avg loss: 0.6669, avg cost: 0.2601, Accuracy:90.33%
