(C:\Users\User\Anaconda3\envs\py35) C:\Users\User>python C:\Users\User\Documents\CENGs\Thesis\edanur\BadaNet\EENets\main.py --epochs 20 --filters 4 --lamb 0.9
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 4, 28, 28]              40
       BatchNorm2d-2            [-1, 4, 28, 28]               8
              ReLU-3            [-1, 4, 28, 28]               0
            Conv2d-4            [-1, 4, 28, 28]             148
       BatchNorm2d-5            [-1, 4, 28, 28]               8
              ReLU-6            [-1, 4, 28, 28]               0
            Conv2d-7            [-1, 4, 28, 28]             148
 AdaptiveAvgPool2d-8              [-1, 4, 1, 1]               0
            Linear-9                   [-1, 10]              50
          Softmax-10                   [-1, 10]               0
           Linear-11                    [-1, 1]               5
          Sigmoid-12                    [-1, 1]               0
      BatchNorm2d-13            [-1, 4, 28, 28]               8
             ReLU-14            [-1, 4, 28, 28]               0
           Conv2d-15            [-1, 8, 14, 14]             296
      BatchNorm2d-16            [-1, 8, 14, 14]              16
             ReLU-17            [-1, 8, 14, 14]               0
           Conv2d-18            [-1, 8, 14, 14]             584
           Conv2d-19            [-1, 8, 14, 14]              40
AdaptiveAvgPool2d-20              [-1, 8, 1, 1]               0
           Linear-21                   [-1, 10]              90
          Softmax-22                   [-1, 10]               0
           Linear-23                    [-1, 1]               9
          Sigmoid-24                    [-1, 1]               0
      BatchNorm2d-25            [-1, 8, 14, 14]              16
             ReLU-26            [-1, 8, 14, 14]               0
           Conv2d-27             [-1, 16, 7, 7]           1,168
      BatchNorm2d-28             [-1, 16, 7, 7]              32
             ReLU-29             [-1, 16, 7, 7]               0
           Conv2d-30             [-1, 16, 7, 7]           2,320
           Conv2d-31             [-1, 16, 7, 7]             144
      BatchNorm2d-32             [-1, 16, 7, 7]              32
             ReLU-33             [-1, 16, 7, 7]               0
AdaptiveAvgPool2d-34             [-1, 16, 1, 1]               0
           Linear-35                   [-1, 10]             170
          Softmax-36                   [-1, 10]               0
================================================================
Total params: 5,332
Trainable params: 5,332
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.34
Params size (MB): 0.02
Estimated Total Size (MB): 0.36
----------------------------------------------------------------
 1:Test set avg time: 0.7464msec Avg loss: 1.1262, Avg cost: 0.9767, Exits: <0,315,9685>, Accuracy:93.08%
 2:Test set avg time: 0.6616msec Avg loss: 1.0296, Avg cost: 0.9561, Exits: <0,593,9407>, Accuracy:95.08%
 3:Test set avg time: 0.6677msec Avg loss: 0.9641, Avg cost: 0.9418, Exits: <0,786,9214>, Accuracy:96.47%
 4:Test set avg time: 0.6659msec Avg loss: 0.9000, Avg cost: 0.8460, Exits: <951,899,8150>, Accuracy:96.24%
 5:Test set avg time: 0.6105msec Avg loss: 0.8890, Avg cost: 0.8259, Exits: <1177,889,7934>, Accuracy:96.15%
 6:Test set avg time: 0.6008msec Avg loss: 0.8577, Avg cost: 0.8299, Exits: <1116,911,7973>, Accuracy:97.13%
 7:Test set avg time: 0.6019msec Avg loss: 0.8510, Avg cost: 0.8369, Exits: <1067,877,8056>, Accuracy:97.20%
 8:Test set avg time: 0.6080msec Avg loss: 0.9176, Avg cost: 0.8118, Exits: <1141,1125,7734>, Accuracy:95.61%
 9:Test set avg time: 0.6084msec Avg loss: 0.8780, Avg cost: 0.8138, Exits: <1188,1039,7773>, Accuracy:96.53%
10:Test set avg time: 0.5916msec Avg loss: 1.0289, Avg cost: 0.7928, Exits: <1123,1404,7473>, Accuracy:93.27%
11:Test set avg time: 0.5980msec Avg loss: 0.8528, Avg cost: 0.8246, Exits: <1187,894,7919>, Accuracy:97.09%
12:Test set avg time: 0.5933msec Avg loss: 0.9699, Avg cost: 0.7911, Exits: <1157,1385,7458>, Accuracy:94.10%
13:Test set avg time: 0.6286msec Avg loss: 0.8257, Avg cost: 0.8239, Exits: <1144,958,7898>, Accuracy:97.70%
14:Test set avg time: 0.5642msec Avg loss: 1.0219, Avg cost: 0.7507, Exits: <1202,1875,6923>, Accuracy:93.29%
15:Test set avg time: 0.5956msec Avg loss: 0.8305, Avg cost: 0.8281, Exits: <1123,927,7950>, Accuracy:97.56%
16:Test set avg time: 0.5689msec Avg loss: 0.9411, Avg cost: 0.7126, Exits: <1202,2389,6409>, Accuracy:94.20%
17:Test set avg time: 0.5697msec Avg loss: 0.8241, Avg cost: 0.7543, Exits: <1131,1914,6955>, Accuracy:96.54%
18:Test set avg time: 0.5789msec Avg loss: 0.7919, Avg cost: 0.7697, Exits: <1108,1734,7158>, Accuracy:97.25%
19:Test set avg time: 0.5698msec Avg loss: 0.7887, Avg cost: 0.7395, Exits: <1085,2171,6744>, Accuracy:97.05%
20:Test set avg time: 0.6814msec Avg loss: 0.8017, Avg cost: 0.7861, Exits: <1120,1498,7382>, Accuracy:97.46%
Best avg loss: 0.8257, avg cost: 0.8239, Accuracy:97.70%
