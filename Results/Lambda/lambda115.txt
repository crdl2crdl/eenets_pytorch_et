(C:\Users\User\Anaconda3\envs\py35) C:\Users\User>python C:\Users\User\Documents\CENGs\Thesis\edanur\BadaNet\EENets\main.py --epochs 20 --filters 4 --lamb 1.15
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 4, 28, 28]              40
       BatchNorm2d-2            [-1, 4, 28, 28]               8
              ReLU-3            [-1, 4, 28, 28]               0
            Conv2d-4            [-1, 4, 28, 28]             148
       BatchNorm2d-5            [-1, 4, 28, 28]               8
              ReLU-6            [-1, 4, 28, 28]               0
            Conv2d-7            [-1, 4, 28, 28]             148
 AdaptiveAvgPool2d-8              [-1, 4, 1, 1]               0
            Linear-9                   [-1, 10]              50
          Softmax-10                   [-1, 10]               0
           Linear-11                    [-1, 1]               5
          Sigmoid-12                    [-1, 1]               0
      BatchNorm2d-13            [-1, 4, 28, 28]               8
             ReLU-14            [-1, 4, 28, 28]               0
           Conv2d-15            [-1, 8, 14, 14]             296
      BatchNorm2d-16            [-1, 8, 14, 14]              16
             ReLU-17            [-1, 8, 14, 14]               0
           Conv2d-18            [-1, 8, 14, 14]             584
           Conv2d-19            [-1, 8, 14, 14]              40
AdaptiveAvgPool2d-20              [-1, 8, 1, 1]               0
           Linear-21                   [-1, 10]              90
          Softmax-22                   [-1, 10]               0
           Linear-23                    [-1, 1]               9
          Sigmoid-24                    [-1, 1]               0
      BatchNorm2d-25            [-1, 8, 14, 14]              16
             ReLU-26            [-1, 8, 14, 14]               0
           Conv2d-27             [-1, 16, 7, 7]           1,168
      BatchNorm2d-28             [-1, 16, 7, 7]              32
             ReLU-29             [-1, 16, 7, 7]               0
           Conv2d-30             [-1, 16, 7, 7]           2,320
           Conv2d-31             [-1, 16, 7, 7]             144
      BatchNorm2d-32             [-1, 16, 7, 7]              32
             ReLU-33             [-1, 16, 7, 7]               0
AdaptiveAvgPool2d-34             [-1, 16, 1, 1]               0
           Linear-35                   [-1, 10]             170
          Softmax-36                   [-1, 10]               0
================================================================
Total params: 5,332
Trainable params: 5,332
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.34
Params size (MB): 0.02
Estimated Total Size (MB): 0.36
----------------------------------------------------------------
 1:Test set avg time: 0.5948msec Avg loss: 1.4768, Avg cost: 0.7312, Exits: <59,3559,6382>, Accuracy:79.94%
 2:Test set avg time: 0.6448msec Avg loss: 1.2243, Avg cost: 0.8053, Exits: <399,2135,7466>, Accuracy:91.19%
 3:Test set avg time: 0.6411msec Avg loss: 1.1837, Avg cost: 0.7900, Exits: <386,2358,7256>, Accuracy:92.11%
 4:Test set avg time: 0.5959msec Avg loss: 1.3689, Avg cost: 0.6671, Exits: <293,4134,5573>, Accuracy:84.65%
 5:Test set avg time: 0.5880msec Avg loss: 1.3974, Avg cost: 0.6342, Exits: <293,4579,5128>, Accuracy:84.29%
 6:Test set avg time: 0.5955msec Avg loss: 1.1524, Avg cost: 0.7108, Exits: <245,3604,6151>, Accuracy:91.56%
 7:Test set avg time: 0.5856msec Avg loss: 1.2805, Avg cost: 0.6133, Exits: <252,4912,4836>, Accuracy:86.94%
 8:Test set avg time: 0.6355msec Avg loss: 1.1536, Avg cost: 0.7650, Exits: <170,2964,6866>, Accuracy:91.59%
 9:Test set avg time: 0.6323msec Avg loss: 1.1333, Avg cost: 0.7400, Exits: <119,3366,6515>, Accuracy:92.56%
10:Test set avg time: 0.5381msec Avg loss: 2.6698, Avg cost: 0.4162, Exits: <147,7707,2146>, Accuracy:65.86%
11:Test set avg time: 0.5537msec Avg loss: 2.6610, Avg cost: 0.4500, Exits: <123,7279,2598>, Accuracy:67.26%
12:Test set avg time: 0.5611msec Avg loss: 1.8115, Avg cost: 0.5126, Exits: <132,6422,3446>, Accuracy:80.88%
13:Test set avg time: 0.6183msec Avg loss: 1.1551, Avg cost: 0.7135, Exits: <95,3754,6151>, Accuracy:91.73%
14:Test set avg time: 0.5458msec Avg loss: 1.9244, Avg cost: 0.4578, Exits: <19,7304,2677>, Accuracy:84.37%
15:Test set avg time: 0.5772msec Avg loss: 1.4124, Avg cost: 0.5179, Exits: <59,6442,3499>, Accuracy:88.86%
16:Test set avg time: 0.5853msec Avg loss: 1.2166, Avg cost: 0.5649, Exits: <18,5858,4124>, Accuracy:89.65%
17:Test set avg time: 0.5445msec Avg loss: 1.9603, Avg cost: 0.4427, Exits: <47,7473,2480>, Accuracy:82.00%
18:Test set avg time: 0.5527msec Avg loss: 1.7988, Avg cost: 0.4459, Exits: <16,7468,2516>, Accuracy:83.94%
19:Test set avg time: 0.5723msec Avg loss: 1.2906, Avg cost: 0.5106, Exits: <22,6586,3392>, Accuracy:89.67%
20:Test set avg time: 0.5578msec Avg loss: 1.7247, Avg cost: 0.4595, Exits: <48,7245,2707>, Accuracy:85.93%
Best avg loss: 1.1333, avg cost: 0.7400, Accuracy:92.56%
